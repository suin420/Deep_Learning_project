{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745cb8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6894a",
   "metadata": {},
   "source": [
    "15d97757b2958ed1ef70866cae13741e3b7c970c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0825cbfb",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0361b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce GTX 1080, 8120MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/Deep_Project/final_10/yolo/yolov5/wandb/run-20231128_123729-39mznbu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/muikaald/YOLOv5/runs/39mznbu6' target=\"_blank\">lively-field-22</a></strong> to <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/muikaald/YOLOv5/runs/39mznbu6' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/39mznbu6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/train/labels.cache... 10440 images, 0 backgrounds, 0 corrupt: 100% 10440/10440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/valid/labels.cache... 1260 images, 0 backgrounds, 0 corrupt: 100% 1260/1260 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.93 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp9/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp9\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/9     0.967G    0.05781    0.02111    0.06214         31        224: 100% 653/653 [03:13<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:14<00:00,  2.83it/s]\n",
      "                   all       1260       1908      0.135      0.729       0.19      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/9     0.967G    0.03706    0.01545    0.04219         35        224: 100% 653/653 [03:06<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.94it/s]\n",
      "                   all       1260       1908      0.849      0.881      0.918      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/9     0.967G    0.03515    0.01422    0.01637         32        224: 100% 653/653 [03:07<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.98it/s]\n",
      "                   all       1260       1908      0.964      0.953      0.983       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/9     0.967G    0.03002    0.01359     0.0111         27        224: 100% 653/653 [03:02<00:00,  3.58it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.94it/s]\n",
      "                   all       1260       1908      0.922      0.927      0.969      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/9     0.967G    0.02787     0.0128    0.00883         25        224: 100% 653/653 [03:01<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                   all       1260       1908      0.938      0.957      0.981      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        5/9     0.967G     0.0247    0.01202   0.007571         25        224: 100% 653/653 [03:03<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.97it/s]\n",
      "                   all       1260       1908      0.944      0.965      0.984       0.85\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        6/9     0.967G    0.02267    0.01127    0.00588         17        224: 100% 653/653 [03:03<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.91it/s]\n",
      "                   all       1260       1908      0.967       0.96      0.986      0.862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        7/9     0.967G    0.02072    0.01086   0.005248         29        224: 100% 653/653 [03:03<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.99it/s]\n",
      "                   all       1260       1908      0.985      0.951      0.988      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        8/9     0.967G    0.01917    0.01032   0.004228         24        224: 100% 653/653 [03:05<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.87it/s]\n",
      "                   all       1260       1908      0.968      0.974      0.992      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        9/9     0.967G    0.01773   0.009875   0.003564         24        224: 100% 653/653 [03:01<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:13<00:00,  2.94it/s]\n",
      "                   all       1260       1908       0.97      0.977      0.991      0.906\n",
      "\n",
      "10 epochs completed in 0.558 hours.\n",
      "Optimizer stripped from runs/train/exp9/weights/last.pt, 14.3MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/train/exp9/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp9/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [00:15<00:00,  2.61it/s]\n",
      "                   all       1260       1908       0.97      0.977      0.991      0.906\n",
      "                  ÏΩîÏπ¥ÏΩúÎùº       1260        234      0.962          1      0.995      0.934\n",
      "                    ÌôòÌÉÄ       1260        186      0.997          1      0.995      0.938\n",
      "               Î†àÏì∞ÎπÑ ÎßàÏùºÎìú       1260        174          1      0.936      0.995      0.944\n",
      "                   Î∞ÄÌÇ§Ïä§       1260        162      0.989      0.988      0.994      0.852\n",
      "               Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº       1260        210      0.998          1      0.995      0.937\n",
      "                   Ïõ∞ÏπòÏä§       1260        162       0.98          1      0.995      0.905\n",
      "                  Îç∞ÎØ∏ÏÜåÎã§       1260        228      0.995      0.966      0.995      0.887\n",
      "                 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§       1260        180      0.967       0.97      0.993      0.886\n",
      "                  Î¥âÎ¥âÌè¨ÎèÑ       1260        216      0.855      0.926      0.968      0.898\n",
      "                   Îç∞ÏûêÏôÄ       1260        156      0.959      0.987       0.99      0.882\n",
      "Results saved to \u001b[1mruns/train/exp9\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/precision</td><td>‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/recall</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/box_loss</td><td>‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train/cls_loss</td><td>‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/obj_loss</td><td>‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>val/box_loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/cls_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/obj_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr0</td><td>‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr1</td><td>‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>x/lr2</td><td>‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>9</td></tr><tr><td>best/mAP_0.5</td><td>0.99149</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.90612</td></tr><tr><td>best/precision</td><td>0.97021</td></tr><tr><td>best/recall</td><td>0.97724</td></tr><tr><td>metrics/mAP_0.5</td><td>0.99148</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.90622</td></tr><tr><td>metrics/precision</td><td>0.9702</td></tr><tr><td>metrics/recall</td><td>0.97726</td></tr><tr><td>train/box_loss</td><td>0.01773</td></tr><tr><td>train/cls_loss</td><td>0.00356</td></tr><tr><td>train/obj_loss</td><td>0.00987</td></tr><tr><td>val/box_loss</td><td>0.013</td></tr><tr><td>val/cls_loss</td><td>0.0008</td></tr><tr><td>val/obj_loss</td><td>0.00279</td></tr><tr><td>x/lr0</td><td>0.00208</td></tr><tr><td>x/lr1</td><td>0.00208</td></tr><tr><td>x/lr2</td><td>0.00208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-field-22</strong> at: <a href='https://wandb.ai/muikaald/YOLOv5/runs/39mznbu6' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/39mznbu6</a><br/>Synced 6 W&B file(s), 17 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231128_123729-39mznbu6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "#%run train.py --img 224 --batch 16 --epochs 15 --data data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --device 0 --lr0 0.001 --lrf 0.0001 --degrees 10.0 --translate 0.2 --scale 0.8 --shear 0.2 --momentum 0.9 --weight_decay 0.0001 --mosaic 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7801e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.220-py3-none-any.whl (645 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m646.0/646.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0)\n",
      "Collecting thop>=0.1.1\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.6.3)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.9.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.39.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.11.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Installing collected packages: opencv-python, thop, ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts ultralytics and yolo are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed opencv-python-4.8.1.78 thop-0.1.1.post2209072238 ultralytics-8.0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/work/.netrc\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=models/yolov5m.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=8, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['Pillow>=10.0.1', 'setuptools>=65.5.1'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cuml 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\n",
      "cudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\n",
      "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "librosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\n",
      "kfp 1.8.20 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.86.0 which is incompatible.\n",
      "kfp 1.8.20 requires PyYAML<6,>=5.3, but you have pyyaml 6.0 which is incompatible.\n",
      "dask-cuda 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\n",
      "cuml 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\n",
      "cudf 23.4.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
      "beatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow>=10.0.1\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting setuptools>=65.5.1\n",
      "  Downloading setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m176.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools, Pillow\n",
      "Successfully installed Pillow-10.1.0 setuptools-69.0.2\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 12.0s, installed 2 packages: ['Pillow>=10.0.1', 'setuptools>=65.5.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce GTX 1080, 8120MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmuikaald\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316e3cc4e5924747844acf1186653f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666999248166879, max=1.0)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/Deep_Project/final_10/yolo/yolov5/wandb/run-20231129_143951-pimnerrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/muikaald/YOLOv5/runs/pimnerrb' target=\"_blank\">super-smoke-26</a></strong> to <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/muikaald/YOLOv5/runs/pimnerrb' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/pimnerrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.Unicode.ttf to /home/work/.config/Ultralytics/Arial.Unicode.ttf...\n",
      "100% 22.2M/22.2M [00:00<00:00, 50.9MB/s]\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     60615  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m summary: 291 layers, 20907687 parameters, 20907687 gradients, 48.3 GFLOPs\n",
      "\n",
      "Transferred 474/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/train/labels.cache... 10440 images, 0 backgrounds, 0 corrupt: 100% 10440/10440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/valid/labels.cache... 1260 images, 0 backgrounds, 0 corrupt: 100% 1260/1260 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.93 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.83G     0.1156    0.01941    0.06599         30        224:   0% 0/1305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/work/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        0/4      1.85G      0.115    0.01759    0.06712         26        224:   1% 13/1305 [00:04<03:12,  6.70it/s]\n",
      "        0/4      1.85G      0.115    0.01736    0.06688         22        224:   1% 14/1305 [00:04<04:45,  4.52it/s]\n",
      "100% 755k/755k [00:00<00:00, 4.52MB/s].01796     0.0668         37        224:   1% 15/1305 [00:05<04:10,  5.15it/s]\n",
      "        0/4      1.86G    0.05046     0.0201    0.06151         31        224: 100% 1305/1305 [03:32<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:17<00:00,  4.44it/s]\n",
      "                   all       1260       1908      0.252      0.591      0.334      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.86G    0.03347    0.01404    0.03839         35        224: 100% 1305/1305 [03:29<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:17<00:00,  4.61it/s]\n",
      "                   all       1260       1908      0.936      0.941      0.979      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.86G    0.03071    0.01284    0.01402         32        224: 100% 1305/1305 [03:26<00:00,  6.31it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:16<00:00,  4.89it/s]\n",
      "                   all       1260       1908      0.943      0.974      0.987      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.86G    0.02505    0.01199   0.009556         27        224: 100% 1305/1305 [03:25<00:00,  6.34it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:16<00:00,  4.84it/s]\n",
      "                   all       1260       1908      0.957      0.956      0.986      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.86G    0.02384    0.01124   0.007392         25        224: 100% 1305/1305 [03:23<00:00,  6.43it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:16<00:00,  4.90it/s]\n",
      "                   all       1260       1908      0.954      0.978      0.987      0.869\n",
      "\n",
      "5 epochs completed in 0.319 hours.\n",
      "Optimizer stripped from runs/train/exp13/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from runs/train/exp13/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating runs/train/exp13/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 212 layers, 20889303 parameters, 0 gradients, 48.0 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:17<00:00,  4.61it/s]\n",
      "                   all       1260       1908      0.953      0.977      0.987       0.87\n",
      "                  ÏΩîÏπ¥ÏΩúÎùº       1260        234      0.981          1      0.995      0.905\n",
      "                    ÌôòÌÉÄ       1260        186       0.98      0.989      0.995      0.914\n",
      "               Î†àÏì∞ÎπÑ ÎßàÏùºÎìú       1260        174          1       0.96      0.978      0.919\n",
      "                   Î∞ÄÌÇ§Ïä§       1260        162      0.948      0.994      0.995      0.861\n",
      "               Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº       1260        210      0.987          1      0.995      0.877\n",
      "                   Ïõ∞ÏπòÏä§       1260        162      0.963          1      0.995      0.853\n",
      "                  Îç∞ÎØ∏ÏÜåÎã§       1260        228          1      0.919      0.993      0.855\n",
      "                 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§       1260        180      0.983      0.977      0.992      0.849\n",
      "                  Î¥âÎ¥âÌè¨ÎèÑ       1260        216      0.768      0.935       0.96      0.839\n",
      "                   Îç∞ÏûêÏôÄ       1260        156      0.919          1      0.975      0.826\n",
      "Results saved to \u001b[1mruns/train/exp13\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/precision</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/recall</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/box_loss</td><td>‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>train/cls_loss</td><td>‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train/obj_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>val/box_loss</td><td>‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>val/cls_loss</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/obj_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr0</td><td>‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr1</td><td>‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ</td></tr><tr><td>x/lr2</td><td>‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>4</td></tr><tr><td>best/mAP_0.5</td><td>0.98736</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.86943</td></tr><tr><td>best/precision</td><td>0.95351</td></tr><tr><td>best/recall</td><td>0.97807</td></tr><tr><td>metrics/mAP_0.5</td><td>0.98712</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.86983</td></tr><tr><td>metrics/precision</td><td>0.9529</td></tr><tr><td>metrics/recall</td><td>0.97748</td></tr><tr><td>train/box_loss</td><td>0.02384</td></tr><tr><td>train/cls_loss</td><td>0.00739</td></tr><tr><td>train/obj_loss</td><td>0.01124</td></tr><tr><td>val/box_loss</td><td>0.01331</td></tr><tr><td>val/cls_loss</td><td>0.0025</td></tr><tr><td>val/obj_loss</td><td>0.00305</td></tr><tr><td>x/lr0</td><td>0.00406</td></tr><tr><td>x/lr1</td><td>0.00406</td></tr><tr><td>x/lr2</td><td>0.00406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-smoke-26</strong> at: <a href='https://wandb.ai/muikaald/YOLOv5/runs/pimnerrb' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/pimnerrb</a><br/>Synced 6 W&B file(s), 14 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231129_143951-pimnerrb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "#%run train.py --img 224 --batch 8 --epochs 5 --data data/data.yaml --cfg models/yolov5m.yaml --weights yolov5m.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4a8fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce GTX 1080, 8120MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68fc153b5a24d53a1cd98992be34d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669676173478365, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/Deep_Project/final_10/yolo/yolov5/wandb/run-20231129_150207-gv491467</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/muikaald/YOLOv5/runs/gv491467' target=\"_blank\">misunderstood-thunder-27</a></strong> to <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/muikaald/YOLOv5' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/muikaald/YOLOv5/runs/gv491467' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/gv491467</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/train/labels.cache... 10440 images, 0 backgrounds, 0 corrupt: 100% 10440/10440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/valid/labels.cache... 1260 images, 0 backgrounds, 0 corrupt: 100% 1260/1260 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.93 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp14/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp14\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/9      1.19G    0.05888    0.02124    0.06211         24        224: 100% 327/327 [02:53<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:15<00:00,  1.28it/s]\n",
      "                   all       1260       1908      0.156      0.706        0.2      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/9      1.19G    0.03752     0.0154    0.04175         35        224: 100% 327/327 [02:54<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.35it/s]\n",
      "                   all       1260       1908      0.818      0.899      0.911       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/9       1.2G    0.03587    0.01413    0.01682         39        224: 100% 327/327 [02:53<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.37it/s]\n",
      "                   all       1260       1908      0.891      0.838      0.898      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/9       1.2G    0.03048    0.01341    0.01074         27        224: 100% 327/327 [02:52<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.34it/s]\n",
      "                   all       1260       1908      0.931       0.96      0.983      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/9       1.2G    0.02778    0.01253   0.008044         30        224: 100% 327/327 [02:47<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.34it/s]\n",
      "                   all       1260       1908      0.936      0.963      0.987      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        5/9       1.2G    0.02484     0.0119   0.007072         25        224: 100% 327/327 [02:50<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.42it/s]\n",
      "                   all       1260       1908      0.952      0.971      0.988      0.842\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        6/9       1.2G     0.0225    0.01113   0.005714         21        224: 100% 327/327 [02:53<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:13<00:00,  1.43it/s]\n",
      "                   all       1260       1908      0.971       0.97       0.99      0.862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        7/9       1.2G     0.0207    0.01076   0.004842         29        224: 100% 327/327 [02:53<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.36it/s]\n",
      "                   all       1260       1908      0.966       0.97       0.99      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        8/9       1.2G    0.01892    0.01012   0.004011         26        224: 100% 327/327 [02:52<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.38it/s]\n",
      "                   all       1260       1908      0.972      0.974      0.992      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        9/9       1.2G    0.01748   0.009707   0.003408         24        224: 100% 327/327 [02:53<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:14<00:00,  1.41it/s]\n",
      "                   all       1260       1908      0.977      0.978      0.993      0.911\n",
      "\n",
      "10 epochs completed in 0.527 hours.\n",
      "Optimizer stripped from runs/train/exp14/weights/last.pt, 14.3MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/train/exp14/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp14/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:13<00:00,  1.50it/s]\n",
      "                   all       1260       1908      0.977      0.978      0.993      0.911\n",
      "                  ÏΩîÏπ¥ÏΩúÎùº       1260        234       0.99          1      0.995      0.943\n",
      "                    ÌôòÌÉÄ       1260        186      0.995          1      0.995       0.93\n",
      "               Î†àÏì∞ÎπÑ ÎßàÏùºÎìú       1260        174      0.997      0.937      0.993      0.941\n",
      "                   Î∞ÄÌÇ§Ïä§       1260        162      0.985      0.994      0.995      0.863\n",
      "               Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº       1260        210      0.998          1      0.995       0.93\n",
      "                   Ïõ∞ÏπòÏä§       1260        162      0.964          1      0.995      0.917\n",
      "                  Îç∞ÎØ∏ÏÜåÎã§       1260        228      0.995      0.936      0.993      0.887\n",
      "                 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§       1260        180          1       0.98      0.995      0.893\n",
      "                  Î¥âÎ¥âÌè¨ÎèÑ       1260        216      0.907      0.935      0.982      0.904\n",
      "                   Îç∞ÏûêÏôÄ       1260        156      0.941      0.994      0.992      0.899\n",
      "Results saved to \u001b[1mruns/train/exp14\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/precision</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>metrics/recall</td><td>‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/box_loss</td><td>‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train/cls_loss</td><td>‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/obj_loss</td><td>‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>val/box_loss</td><td>‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/cls_loss</td><td>‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/obj_loss</td><td>‚ñà‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr0</td><td>‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>x/lr1</td><td>‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>x/lr2</td><td>‚ñÇ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>9</td></tr><tr><td>best/mAP_0.5</td><td>0.99299</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.91063</td></tr><tr><td>best/precision</td><td>0.97714</td></tr><tr><td>best/recall</td><td>0.97756</td></tr><tr><td>metrics/mAP_0.5</td><td>0.99299</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.91067</td></tr><tr><td>metrics/precision</td><td>0.9772</td></tr><tr><td>metrics/recall</td><td>0.97757</td></tr><tr><td>train/box_loss</td><td>0.01748</td></tr><tr><td>train/cls_loss</td><td>0.00341</td></tr><tr><td>train/obj_loss</td><td>0.00971</td></tr><tr><td>val/box_loss</td><td>0.01307</td></tr><tr><td>val/cls_loss</td><td>0.00067</td></tr><tr><td>val/obj_loss</td><td>0.00272</td></tr><tr><td>x/lr0</td><td>0.00208</td></tr><tr><td>x/lr1</td><td>0.00208</td></tr><tr><td>x/lr2</td><td>0.00208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-thunder-27</strong> at: <a href='https://wandb.ai/muikaald/YOLOv5/runs/gv491467' target=\"_blank\">https://wandb.ai/muikaald/YOLOv5/runs/gv491467</a><br/>Synced 6 W&B file(s), 17 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231129_150207-gv491467/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "#%run train.py --img 224 --batch 32 --epochs 10 --data data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896bd1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch-med.yaml, epochs=10, batch_size=32, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11020MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/train/labels.cache... 10440 images, 0 backgrounds, 0 corrupt: 100% 10440/10440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/valid/labels.cache... 1260 images, 0 backgrounds, 0 corrupt: 100% 1260/1260 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.93 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp24/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp24\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/9     0.984G    0.06589    0.01703    0.03812         31        224: 100% 327/327 [02:32<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:12<00:00,  1.62it/s]\n",
      "                   all       1260       1908      0.101      0.818      0.125     0.0833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/9      1.25G    0.04091    0.01242    0.03624         26        224: 100% 327/327 [02:30<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.73it/s]\n",
      "                   all       1260       1908      0.106      0.837      0.188      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/9      1.26G    0.03724    0.01121    0.03283         22        224: 100% 327/327 [02:30<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:12<00:00,  1.66it/s]\n",
      "                   all       1260       1908      0.328      0.662      0.423      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/9      1.26G    0.03435    0.01051    0.02088         45        224: 100% 327/327 [02:28<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.72it/s]\n",
      "                   all       1260       1908      0.806      0.886      0.891      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/9      1.26G    0.03259    0.01014    0.01136         16        224: 100% 327/327 [02:28<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.77it/s]\n",
      "                   all       1260       1908       0.95      0.944      0.982      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        5/9      1.26G    0.03007   0.009713   0.008177         33        224: 100% 327/327 [02:33<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.67it/s]\n",
      "                   all       1260       1908      0.957      0.954      0.982      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        6/9      1.26G    0.02849   0.009329   0.007081         24        224: 100% 327/327 [02:35<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                   all       1260       1908      0.921      0.954       0.98      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        7/9      1.26G    0.02707   0.009208   0.006121         26        224: 100% 327/327 [02:32<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:12<00:00,  1.65it/s]\n",
      "                   all       1260       1908      0.948      0.976      0.988      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        8/9      1.26G    0.02533   0.008691   0.005288         28        224: 100% 327/327 [02:29<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.70it/s]\n",
      "                   all       1260       1908      0.959       0.95      0.987      0.862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        9/9      1.26G    0.02401   0.008457    0.00482         28        224: 100% 327/327 [02:32<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:11<00:00,  1.76it/s]\n",
      "                   all       1260       1908      0.968      0.958      0.991      0.894\n",
      "\n",
      "10 epochs completed in 0.459 hours.\n",
      "Optimizer stripped from runs/train/exp24/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp24/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp24/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:10<00:00,  1.90it/s]\n",
      "                   all       1260       1908      0.968      0.958      0.991      0.894\n",
      "                  ÏΩîÏπ¥ÏΩúÎùº       1260        234       0.99          1      0.995       0.91\n",
      "                    ÌôòÌÉÄ       1260        186          1      0.983      0.995      0.942\n",
      "               Î†àÏì∞ÎπÑ ÎßàÏùºÎìú       1260        174       0.96      0.966      0.992      0.938\n",
      "                   Î∞ÄÌÇ§Ïä§       1260        162      0.999      0.994      0.995      0.847\n",
      "               Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº       1260        210      0.987      0.995      0.995      0.907\n",
      "                   Ïõ∞ÏπòÏä§       1260        162      0.967          1      0.995      0.902\n",
      "                  Îç∞ÎØ∏ÏÜåÎã§       1260        228          1      0.875      0.994       0.87\n",
      "                 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§       1260        180      0.994      0.878      0.992      0.858\n",
      "                  Î¥âÎ¥âÌè¨ÎèÑ       1260        216      0.817      0.933      0.966       0.88\n",
      "                   Îç∞ÏûêÏôÄ       1260        156      0.967      0.954      0.992      0.889\n",
      "Results saved to \u001b[1mruns/train/exp24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#%run train.py --img 224 --batch 32 --epochs 10 --hyp data/hyps/hyp.scratch-med.yaml --data data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be184268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.custom.yaml, epochs=3, batch_size=8, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11020MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.8, weight_decay=0.0003, warmup_epochs=2.0, warmup_momentum=0.78, warmup_bias_lr=0.1, box=0.05, cls=0.4, cls_pw=0.5, obj=0.51728, obj_pw=0.67198, iou_t=0.2, anchor_t=3.3744, fl_gamma=0.0, hsv_h=0.01041, hsv_s=0.54703, hsv_v=0.27739, degrees=0.0, translate=0.04591, scale=0.65544, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.6, mosaic=0.85, mixup=0.04266, copy_paste=0.0, anchors=3.412\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "Overriding model.yaml anchors with anchors=3.412\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0003), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/train/labels.cache... 10440 images, 0 backgrounds, 0 corrupt: 100% 10440/10440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/work/Deep_Project/final_10/final_data/valid/labels.cache... 1260 images, 0 backgrounds, 0 corrupt: 100% 1260/1260 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 15984 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9078: 100% 1000/1000 [00:01<00:00, 558.19it/s]\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.30: 0.9991 best possible recall, 8.87 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=224, metric_all=0.645/0.908-mean/best, past_thr=0.651-mean: 69,107, 65,125, 62,162, 79,154, 111,129, 82,210, 109,207, 139,209, 195,194\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\n",
      "Plotting labels to runs/train/exp25/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp25\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/2      0.34G    0.05611    0.01347     0.0303         26        224: 100% 1305/1305 [02:31<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:10<00:00,  7.26it/s]\n",
      "                   all       1260       1908    0.00829      0.996      0.119     0.0763\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/2     0.367G     0.0329    0.01102    0.02952         23        224: 100% 1305/1305 [02:27<00:00,  8.87it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:10<00:00,  7.26it/s]\n",
      "                   all       1260       1908     0.0306      0.997      0.134      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/2     0.367G     0.0263    0.00862    0.02942         31        224: 100% 1305/1305 [02:25<00:00,  8.97it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:11<00:00,  7.15it/s]\n",
      "                   all       1260       1908      0.044      0.999      0.139      0.117\n",
      "\n",
      "3 epochs completed in 0.134 hours.\n",
      "Optimizer stripped from runs/train/exp25/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp25/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp25/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 79/79 [00:11<00:00,  6.94it/s]\n",
      "                   all       1260       1908      0.044      0.999      0.139      0.117\n",
      "                  ÏΩîÏπ¥ÏΩúÎùº       1260        234     0.0617          1      0.164      0.145\n",
      "                    ÌôòÌÉÄ       1260        186     0.0379          1      0.153      0.135\n",
      "               Î†àÏì∞ÎπÑ ÎßàÏùºÎìú       1260        174     0.0405          1      0.137      0.117\n",
      "                   Î∞ÄÌÇ§Ïä§       1260        162     0.0414          1      0.103     0.0817\n",
      "               Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº       1260        210     0.0492          1      0.183      0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                   Ïõ∞ÏπòÏä§       1260        162     0.0437          1       0.13      0.107\n",
      "                  Îç∞ÎØ∏ÏÜåÎã§       1260        228     0.0553          1      0.106     0.0865\n",
      "                 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§       1260        180     0.0366          1     0.0919     0.0736\n",
      "                  Î¥âÎ¥âÌè¨ÎèÑ       1260        216      0.041          1      0.203      0.167\n",
      "                   Îç∞ÏûêÏôÄ       1260        156     0.0324      0.987      0.122      0.103\n",
      "Results saved to \u001b[1mruns/train/exp25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#%run train.py --img 224 --batch 8 --epochs 3 --hyp data/hyps/hyp.custom.yaml --data data/data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bbf281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2347b5c1",
   "metadata": {},
   "source": [
    "### ÏµúÏ¢Ö Î™®Îç∏Î°ú exp14 ÏÇ¨Ïö©  (runs/train/exp14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc2302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8b267d",
   "metadata": {},
   "source": [
    "## test Image detect ÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebcfc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20a04b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/work/Deep_Project/final_10/yolo/yolov5/runs/train/exp14/weights/best.pt'], source=/home/work/Deep_Project/final_10/final_data/test/images, data=data/coco128.yaml, imgsz=[224, 224], conf_thres=0.8, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11020MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 /home/work/Deep_Project/final_10/final_data/test/images/Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§.jpg: 224x224 1 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§, 3.6ms\n",
      "Speed: 0.2ms pre-process, 3.6ms inference, 2.0ms NMS per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights /home/work/Deep_Project/final_10/yolo/yolov5/runs/train/exp14/weights/best.pt --img 224 --conf 0.8 --source /home/work/Deep_Project/final_10/final_data/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6ba53",
   "metadata": {},
   "source": [
    "## ÏòàÏ∏°Ìïú ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Ï∂îÏ∂ú (Ïù¥ÌõÑ Ï†êÏûêÎ™®ÎìàÍ≥º Ïó∞Í≤∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e7d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (3)\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/work/Deep_Project/final_10/yolo/yolov5/runs/train/exp14/weights/best.pt'], source=/home/work/Deep_Project/final_10/final_data/test/images, data=data/coco128.yaml, imgsz=[224, 224], conf_thres=0.8, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v7.0-247-g3f02fde Python-3.10.10 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11020MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/4 /home/work/Deep_Project/final_10/final_data/test/images/4Í∞ú.png: 224x224 1 ÏΩîÏπ¥ÏΩúÎùº, 1 ÌôòÌÉÄ, 1 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§, 3.5ms\n",
      "image 2/4 /home/work/Deep_Project/final_10/final_data/test/images/Î™¨Ïä§ÌÑ∞ÏóêÎÑàÏßÄÏö∏Ìä∏Îùº.jpg: 224x224 1 Î™¨Ïä§ÌÑ∞ Ïö∏Ìä∏Îùº, 3.8ms\n",
      "image 3/4 /home/work/Deep_Project/final_10/final_data/test/images/Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§.jpg: 224x224 1 Ïπ†ÏÑ±ÏÇ¨Ïù¥Îã§, 3.7ms\n",
      "image 4/4 /home/work/Deep_Project/final_10/final_data/test/images/ÏΩîÏπ¥ÏΩúÎùº.jpg: 224x224 1 ÏΩîÏπ¥ÏΩúÎùº, 3.5ms\n",
      "Speed: 0.2ms pre-process, 3.6ms inference, 0.9ms NMS per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = \"python detect.py --weights /home/work/Deep_Project/final_10/yolo/yolov5/runs/train/exp14/weights/best.pt --img 224 --conf 0.8 --source /home/work/Deep_Project/final_10/final_data/test/images\"\n",
    "\n",
    "# Î™ÖÎ†π Ïã§Ìñâ Î∞è Í≤∞Í≥º Ï∫°Ï≤ò\n",
    "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(stdout.decode())  # ÌëúÏ§Ä Ï∂úÎ†• Í≤∞Í≥º\n",
    "print(stderr.decode())  # ÏóêÎü¨ Ï∂úÎ†• Í≤∞Í≥º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a063f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7981bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏΩîÏπ¥ÏΩúÎùº\n"
     ]
    }
   ],
   "source": [
    "extracted_text = stderr.decode().split('224x224 ')[-1].split(',')[0]\n",
    "extracted_text= re.sub(r'[\\d\\s]+', '', extracted_text)\n",
    "\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e35598",
   "metadata": {},
   "source": [
    "## Ï†êÏûê Î≤àÏó≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ced9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/Deep_Project/final_10/yolo/yolov5/hangul-braille-converter\n"
     ]
    }
   ],
   "source": [
    "%cd hangul-braille-converter\n",
    "import hbcvt\n",
    "import jumja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2d2a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['„Öã', [[1, 1, 0, 1, 0, 0]]]\n",
      "['„Öó', [[1, 0, 1, 0, 0, 1]]]\n",
      "['Ïπ¥', [[1, 1, 0, 1, 0, 0]]]\n",
      "['„Öã', [[1, 1, 0, 1, 0, 0]]]\n",
      "['„Öó', [[1, 0, 1, 0, 0, 1]]]\n",
      "['„Ñπ', [[0, 1, 0, 0, 0, 0]]]\n",
      "['„Ñπ', [[0, 0, 0, 0, 1, 0]]]\n",
      "['„Öè', [[1, 1, 0, 0, 0, 1]]]\n"
     ]
    }
   ],
   "source": [
    "jumja.to_vector(extracted_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f338081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚óè ‚óè\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óè ‚óè\n",
      "‚óè ‚óè\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óè ‚óè\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óè ‚óè\n",
      "‚óã ‚óã\n",
      "‚óè ‚óã\n",
      "‚óã ‚óã\n",
      "‚óã ‚óã\n",
      "‚óã ‚óè\n",
      "‚óã ‚óã\n",
      "‚óè ‚óã\n",
      "‚óè ‚óã\n",
      "‚óã ‚óè\n"
     ]
    }
   ],
   "source": [
    "jumja.to_jumja('ÏΩîÏπ¥ÏΩúÎùº')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6adf44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch2.0, Tensorflow2.11 (kaggle 23.05/Python 3.10 Conda, CUDA 11.3) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
